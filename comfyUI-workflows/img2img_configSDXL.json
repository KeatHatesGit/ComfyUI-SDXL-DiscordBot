{
  "3": {
    "inputs": {
      "seed": [
        "12",
        0
      ],
      "steps": 5,
      "cfg": 1.8,
      "sampler_name": "lcm",
      "scheduler": "sgm_uniform",
      "denoise": 0.9,
      "model": [
        "11",
        0
      ],
      "positive": [
        "17",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "latent_image": [
        "15",
        0
      ]
    },
    "class_type": "KSampler"
  },
  "4": {
    "inputs": {
      "ckpt_name": "lcm_dreamshaperxl.safetensors"
    },
    "class_type": "CheckpointLoaderSimple"
  },
  "7": {
    "inputs": {
      "text": "text, watermark",
      "clip": [
        "11",
        1
      ]
    },
    "class_type": "CLIPTextEncode"
  },
  "8": {
    "inputs": {
      "samples": [
        "3",
        0
      ],
      "vae": [
        "4",
        2
      ]
    },
    "class_type": "VAEDecode"
  },
  "9": {
    "inputs": {
      "filename_prefix": "final_output",
      "images": [
        "8",
        0
      ]
    },
    "class_type": "SaveImage"
  },
  "11": {
    "inputs": {
      "lora_01": "None",
      "strength_01": 1,
      "lora_02": "None",
      "strength_02": 1,
      "lora_03": "None",
      "strength_03": 1,
      "lora_04": "None",
      "strength_04": 1,
      "model": [
        "4",
        0
      ],
      "clip": [
        "4",
        1
      ]
    },
    "class_type": "Lora Loader Stack (rgthree)"
  },
  "12": {
    "inputs": {
      "seed": 61126062341422
    },
    "class_type": "Seed (rgthree)"
  },
  "13": {
    "inputs": {
      "image": "example.png",
      "choose file to upload": "image"
    },
    "class_type": "LoadImage"
  },
  "14": {
    "inputs": {
      "pixels": [
        "13",
        0
      ],
      "vae": [
        "4",
        2
      ]
    },
    "class_type": "VAEEncode"
  },
  "15": {
    "inputs": {
      "amount": 4,
      "samples": [
        "14",
        0
      ]
    },
    "class_type": "RepeatLatentBatch"
  },
  "17": {
    "inputs": {
      "width": 4096,
      "height": 4096,
      "crop_w": 0,
      "crop_h": 0,
      "target_width": 4096,
      "target_height": 4096,
      "text_g": "CLIP_G",
      "text_l": "CLIP_L",
      "clip": [
        "11",
        1
      ]
    },
    "class_type": "CLIPTextEncodeSDXL"
  },
  "21": {
    "inputs": {
      "prompt": "a dog"
    },
    "class_type": "CR Prompt Text"
  },
  "22": {
    "inputs": {
      "prompt": "a dog"
    },
    "class_type": "CR Prompt Text"
  }
}