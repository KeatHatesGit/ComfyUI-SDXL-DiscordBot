{
  "4": {
    "inputs": {
      "ckpt_name": "lcm_dreamshaperxl.safetensors"
    },
    "class_type": "CheckpointLoaderSimple"
  },
  "9": {
    "inputs": {
      "filename_prefix": "final_output",
      "images": [
        "47",
        0
      ]
    },
    "class_type": "SaveImage"
  },
  "11": {
    "inputs": {
      "lora_01": "None",
      "strength_01": 1,
      "lora_02": "None",
      "strength_02": 1,
      "lora_03": "None",
      "strength_03": 1,
      "lora_04": "None",
      "strength_04": 1,
      "model": [
        "4",
        0
      ],
      "clip": [
        "4",
        1
      ]
    },
    "class_type": "Lora Loader Stack (rgthree)"
  },
  "12": {
    "inputs": {
      "seed": 921948267154621
    },
    "class_type": "Seed (rgthree)"
  },
  "13": {
    "inputs": {
      "image": "example.png",
      "choose file to upload": "image"
    },
    "class_type": "LoadImage"
  },
  "32": {
    "inputs": {
      "pos_g": [
        "33",
        0
      ],
      "pos_l": [
        "33",
        0
      ],
      "neg_g": [
        "34",
        0
      ],
      "neg_l": [
        "34",
        0
      ],
      "preset": "preset A",
      "base_width": 4096,
      "base_height": 4096,
      "crop_w": 0,
      "crop_h": 0,
      "target_width": 4096,
      "target_height": 4096,
      "base_clip": [
        "11",
        1
      ]
    },
    "class_type": "CR SDXL Base Prompt Encoder"
  },
  "33": {
    "inputs": {
      "prompt": "a dog"
    },
    "class_type": "CR Prompt Text"
  },
  "34": {
    "inputs": {
      "prompt": "child, children, loli, kid, kids"
    },
    "class_type": "CR Prompt Text"
  },
  "40": {
    "inputs": {
      "model_name": "ESRGAN_4x.pth"
    },
    "class_type": "Upscale Model Loader"
  },
  "41": {
    "inputs": {
      "control_net_name": "sargezt_xl_softedge.safetensors"
    },
    "class_type": "ControlNetLoader"
  },
  "42": {
    "inputs": {
      "strength": 0.8,
      "start_percent": 0,
      "end_percent": 0.7000000000000001,
      "positive": [
        "32",
        0
      ],
      "negative": [
        "32",
        1
      ],
      "control_net": [
        "41",
        0
      ],
      "image": [
        "44",
        0
      ]
    },
    "class_type": "ControlNetApplyAdvanced"
  },
  "43": {
    "inputs": {
      "upscale_model": [
        "40",
        0
      ],
      "image": [
        "13",
        0
      ]
    },
    "class_type": "ImageUpscaleWithModel"
  },
  "44": {
    "inputs": {
      "upscale_method": "lanczos",
      "scale_by": 0.35000000000000003,
      "image": [
        "43",
        0
      ]
    },
    "class_type": "ImageScaleBy"
  },
  "45": {
    "inputs": {
      "pixels": [
        "44",
        0
      ],
      "vae": [
        "4",
        2
      ]
    },
    "class_type": "VAEEncode"
  },
  "46": {
    "inputs": {
      "seed": [
        "12",
        0
      ],
      "steps": 5,
      "cfg": 1.8,
      "sampler_name": "lcm",
      "scheduler": "sgm_uniform",
      "denoise": 0.3,
      "model": [
        "11",
        0
      ],
      "positive": [
        "42",
        0
      ],
      "negative": [
        "42",
        1
      ],
      "latent_image": [
        "45",
        0
      ]
    },
    "class_type": "KSampler"
  },
  "47": {
    "inputs": {
      "samples": [
        "46",
        0
      ],
      "vae": [
        "4",
        2
      ]
    },
    "class_type": "VAEDecode"
  }
}